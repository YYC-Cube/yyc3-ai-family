# Core æ¨¡å—ä½¿ç”¨æŒ‡å—

> BigModel-Z.ai SDK æ ¸å¿ƒæ¨¡å—è¯¦ç»†ä½¿ç”¨è¯´æ˜ã€æŠ€å·§æŒ‡å—å’Œé”™è¯¯è§£å†³

## ğŸ“š ç›®å½•

- [BigModelClient](#bigmodelclient)
- [OpenAICompatibleClient](#openaicompatibleclient)
- [AssistantManager](#assistantmanager)
- [FileManager](#filemanager)
- [KnowledgeBaseManager](#knowledgebasemanager)
- [MultiModalManager](#multimodalmanager)

---

## BigModelClient

### ğŸ“– ä½¿ç”¨è¯´æ˜

BigModelClient æ˜¯ BigModel-Z.ai çš„æ ¸å¿ƒå®¢æˆ·ç«¯ï¼Œæä¾›åŸºç¡€çš„ API è°ƒç”¨åŠŸèƒ½ã€‚

#### åŸºç¡€é…ç½®

```typescript
import { BigModelClient } from '@bigmodel-z/sdk'

const client = new BigModelClient({
  apiKey: 'your-api-key',
  baseUrl: 'https://open.bigmodel.cn/api/',
  timeout: 30000,
})
```

#### åŠ©æ‰‹å¯¹è¯

```typescript
const response = await client.chat(
  '65940acff94777010aa6b796',
  [
    { role: 'user', content: 'ä½ å¥½ï¼Œæˆ‘æ˜¯æ¸…è¨€ï¼Œè¶…å¼€å¿ƒé‡è§ä½ ï¼ğŸ˜º' },
  ],
)

console.log(response.choices[0].message.content)
```

#### æµå¼å¯¹è¯

```typescript
const stream = await client.chatStream(
  '65940acff94777010aa6b796',
  [
    { role: 'user', content: 'ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±' },
  ],
)

for await (const chunk of stream) {
  process.stdout.write(chunk)
}
```

### ğŸ’¡ æŠ€å·§æŒ‡å—

#### 1. è¶…æ—¶è®¾ç½®

æ ¹æ®ç½‘ç»œç¯å¢ƒå’Œè¯·æ±‚å¤æ‚åº¦è°ƒæ•´è¶…æ—¶æ—¶é—´ï¼š

```typescript
const client = new BigModelClient({
  apiKey: 'your-api-key',
  timeout: 60000, // ç½‘ç»œè¾ƒæ…¢æ—¶å¢åŠ è¶…æ—¶æ—¶é—´
})
```

#### 2. é”™è¯¯é‡è¯•

å®ç°æŒ‡æ•°é€€é¿é‡è¯•æœºåˆ¶ï¼š

```typescript
async function chatWithRetry(
  client: BigModelClient,
  assistantId: string,
  messages: any[],
  maxRetries = 3,
) {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await client.chat(assistantId, messages)
    } catch (error) {
      if (i === maxRetries - 1) throw error
      const delay = Math.pow(2, i) * 1000
      await new Promise(resolve => setTimeout(resolve, delay))
    }
  }
}
```

#### 3. æ¶ˆæ¯ç¼“å­˜

ç¼“å­˜å¸¸ç”¨å¯¹è¯ä¸Šä¸‹æ–‡ä»¥æé«˜å“åº”é€Ÿåº¦ï¼š

```typescript
const messageCache = new Map<string, any[]>()

async function getCachedResponse(key: string) {
  if (messageCache.has(key)) {
    return messageCache.get(key)
  }
  const response = await client.chat(assistantId, messages)
  messageCache.set(key, messages)
  return response
}
```

### âŒ å¸¸è§é”™è¯¯åŠè§£å†³

#### é”™è¯¯ 1: API request failed: 401 Unauthorized

**åŸå› ï¼š** API Key æ— æ•ˆæˆ–å·²è¿‡æœŸ

**è§£å†³æ–¹æ³•ï¼š**
1. æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®
2. ç¡®è®¤ API Key æœªè¿‡æœŸ
3. é‡æ–°ç”Ÿæˆ API Key

```typescript
try {
  const response = await client.chat(assistantId, messages)
} catch (error) {
  if (error.message.includes('401')) {
    console.error('API Key æ— æ•ˆï¼Œè¯·æ£€æŸ¥å¹¶æ›´æ–°')
  }
}
```

#### é”™è¯¯ 2: API request failed: 429 Too Many Requests

**åŸå› ï¼š** è¯·æ±‚é¢‘ç‡è¶…é™

**è§£å†³æ–¹æ³•ï¼š**
1. å®ç°è¯·æ±‚é™æµ
2. å¢åŠ è¯·æ±‚é—´éš”
3. ä½¿ç”¨å¤šä¸ª API Key è½®è¯¢

```typescript
class RateLimiter {
  private lastRequestTime = 0
  private minInterval = 1000 // 1 ç§’

  async wait() {
    const now = Date.now()
    const elapsed = now - this.lastRequestTime
    if (elapsed < this.minInterval) {
      await new Promise(resolve => 
        setTimeout(resolve, this.minInterval - elapsed)
      )
    }
    this.lastRequestTime = Date.now()
  }
}

const limiter = new RateLimiter()
await limiter.wait()
const response = await client.chat(assistantId, messages)
```

#### é”™è¯¯ 3: API request failed: timeout

**åŸå› ï¼š** è¯·æ±‚è¶…æ—¶

**è§£å†³æ–¹æ³•ï¼š**
1. å¢åŠ è¶…æ—¶æ—¶é—´
2. æ£€æŸ¥ç½‘ç»œè¿æ¥
3. ä¼˜åŒ–è¯·æ±‚å†…å®¹

```typescript
const client = new BigModelClient({
  apiKey: 'your-api-key',
  timeout: 60000, // å¢åŠ åˆ° 60 ç§’
})
```

---

## OpenAICompatibleClient

### ğŸ“– ä½¿ç”¨è¯´æ˜

OpenAICompatibleClient æä¾› OpenAI API å…¼å®¹çš„æ¥å£ï¼Œæ”¯æŒæ— ç¼è¿ç§»ã€‚

#### åŸºç¡€é…ç½®

```typescript
import { OpenAICompatibleClient } from '@bigmodel-z/sdk'

const client = new OpenAICompatibleClient({
  apiKey: 'your-api-key',
  baseUrl: 'https://open.bigmodel.cn/api/paas/v4/',
  model: 'glm-4',
})
```

#### å¯¹è¯è¡¥å…¨

```typescript
const response = await client.chatCompletion({
  model: 'glm-4',
  messages: [
    { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚' },
    { role: 'user', content: 'ä½ å¥½ï¼' },
  ],
  temperature: 0.7,
  max_tokens: 1000,
})
```

#### æµå¼å¯¹è¯

```typescript
for await (const chunk of client.chatCompletionStream({
  model: 'glm-4',
  messages: [{ role: 'user', content: 'è¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±' }],
})) {
  const content = chunk.choices[0].delta.content
  if (content) {
    process.stdout.write(content)
  }
}
```

### ğŸ’¡ æŠ€å·§æŒ‡å—

#### 1. æ¨¡å‹é€‰æ‹©

æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼š

```typescript
const models = {
  'glm-4': 'é€šç”¨å¯¹è¯',
  'glm-4-plus': 'å¢å¼ºå¯¹è¯',
  'glm-4-flash': 'å¿«é€Ÿå“åº”',
  'glm-3-turbo': 'ç»æµé«˜æ•ˆ',
}

function selectModel(task: string): string {
  if (task.includes('å¿«é€Ÿ')) return 'glm-4-flash'
  if (task.includes('å¤æ‚')) return 'glm-4-plus'
  return 'glm-4'
}
```

#### 2. å‚æ•°è°ƒä¼˜

æ ¹æ®ä»»åŠ¡éœ€æ±‚è°ƒæ•´å‚æ•°ï¼š

```typescript
const config = {
  creative: { temperature: 0.9, top_p: 0.9 },
  balanced: { temperature: 0.7, top_p: 0.7 },
  precise: { temperature: 0.3, top_p: 0.3 },
}

const response = await client.chatCompletion({
  model: 'glm-4',
  messages,
  ...config.balanced,
})
```

#### 3. æµå¼å¤„ç†ä¼˜åŒ–

ä½¿ç”¨ç¼“å†²åŒºæé«˜æµå¼å¤„ç†æ•ˆç‡ï¼š

```typescript
async function processStreamWithBuffer(
  stream: AsyncGenerator<ChatCompletionChunk>,
) {
  const buffer: string[] = []
  let bufferSize = 0
  const maxBufferSize = 1000

  for await (const chunk of stream) {
    const content = chunk.choices[0].delta.content
    if (content) {
      buffer.push(content)
      bufferSize += content.length

      if (bufferSize >= maxBufferSize) {
        process.stdout.write(buffer.join(''))
        buffer.length = 0
        bufferSize = 0
      }
    }
  }

  if (buffer.length > 0) {
    process.stdout.write(buffer.join(''))
  }
}
```

### âŒ å¸¸è§é”™è¯¯åŠè§£å†³

#### é”™è¯¯ 1: Failed to parse chunk

**åŸå› ï¼š** æµå¼å“åº”è§£æå¤±è´¥

**è§£å†³æ–¹æ³•ï¼š**
1. æ£€æŸ¥å“åº”æ ¼å¼
2. æ·»åŠ é”™è¯¯å¤„ç†
3. ä½¿ç”¨ç¼“å†²åŒºå¤„ç†

```typescript
for await (const chunk of stream) {
  try {
    const content = chunk.choices[0].delta.content
    if (content) {
      process.stdout.write(content)
    }
  } catch (error) {
    console.error('è§£æå¤±è´¥ï¼Œè·³è¿‡æ­¤ chunk:', error)
  }
}
```

#### é”™è¯¯ 2: Response body is not readable

**åŸå› ï¼š** å“åº”ä½“ä¸å¯è¯»

**è§£å†³æ–¹æ³•ï¼š**
1. æ£€æŸ¥å“åº”çŠ¶æ€
2. éªŒè¯å“åº”å¤´
3. æ·»åŠ é”™è¯¯æ¢å¤

```typescript
const response = await fetch(url, options)

if (!response.ok) {
  throw new Error(`HTTP ${response.status}: ${response.statusText}`)
}

const reader = response.body?.getReader()
if (!reader) {
  throw new Error('å“åº”ä½“ä¸å¯è¯»ï¼Œè¯·æ£€æŸ¥ API é…ç½®')
}
```

---

## AssistantManager

### ğŸ“– ä½¿ç”¨è¯´æ˜

AssistantManager æä¾›åŠ©æ‰‹ç®¡ç†åŠŸèƒ½ã€‚

#### åˆ—å‡ºåŠ©æ‰‹

```typescript
const assistants = await client.listAssistants()
console.log('å¯ç”¨åŠ©æ‰‹:', assistants)
```

#### åˆ›å»ºå¯¹è¯

```typescript
const conversation = await client.createConversation(
  '65940acff94777010aa6b796',
  'æ–°å¯¹è¯',
)
```

### ğŸ’¡ æŠ€å·§æŒ‡å—

#### 1. åŠ©æ‰‹é€‰æ‹©

æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©åˆé€‚çš„åŠ©æ‰‹ï¼š

```typescript
function selectAssistant(task: string): string {
  const assistants = {
    coding: '65940acff94777010aa6b796',
    writing: '65940acff94777010aa6b797',
    analysis: '65940acff94777010aa6b798',
  }
  return assistants[task] || assistants.coding
}
```

### âŒ å¸¸è§é”™è¯¯åŠè§£å†³

#### é”™è¯¯ 1: Assistant not found

**åŸå› ï¼š** åŠ©æ‰‹ ID ä¸å­˜åœ¨

**è§£å†³æ–¹æ³•ï¼š**
1. æ£€æŸ¥åŠ©æ‰‹ ID
2. åˆ—å‡ºå¯ç”¨åŠ©æ‰‹
3. ä½¿ç”¨æ­£ç¡®çš„åŠ©æ‰‹ ID

```typescript
const assistants = await client.listAssistants()
const validIds = assistants.map(a => a.id)
if (!validIds.includes(assistantId)) {
  throw new Error(`åŠ©æ‰‹ ID ${assistantId} ä¸å­˜åœ¨`)
}
```

---

## FileManager

### ğŸ“– ä½¿ç”¨è¯´æ˜

FileManager æä¾›æ–‡ä»¶ç®¡ç†åŠŸèƒ½ã€‚

#### ä¸Šä¼ æ–‡ä»¶

```typescript
const file = await client.uploadFile('/path/to/file.txt')
console.log('æ–‡ä»¶ ID:', file.id)
```

#### è§£ææ–‡ä»¶

```typescript
const parsed = await client.parseFile(fileId)
console.log('è§£æç»“æœ:', parsed)
```

### ğŸ’¡ æŠ€å·§æŒ‡å—

#### 1. æ–‡ä»¶ç±»å‹æ£€æµ‹

è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç±»å‹ï¼š

```typescript
function getFileType(filename: string): string {
  const ext = filename.split('.').pop()?.toLowerCase()
  const types = {
    'pdf': 'application/pdf',
    'txt': 'text/plain',
    'json': 'application/json',
  }
  return types[ext || 'application/octet-stream']
}
```

### âŒ å¸¸è§é”™è¯¯åŠè§£å†³

#### é”™è¯¯ 1: File too large

**åŸå› ï¼š** æ–‡ä»¶è¶…è¿‡å¤§å°é™åˆ¶

**è§£å†³æ–¹æ³•ï¼š**
1. æ£€æŸ¥æ–‡ä»¶å¤§å°
2. å‹ç¼©æ–‡ä»¶
3. åˆ†å‰²å¤§æ–‡ä»¶

```typescript
const MAX_FILE_SIZE = 10 * 1024 * 1024 // 10MB
const stats = await fs.stat(filePath)

if (stats.size > MAX_FILE_SIZE) {
  throw new Error('æ–‡ä»¶è¿‡å¤§ï¼Œè¯·å‹ç¼©æˆ–åˆ†å‰²')
}
```

---

## KnowledgeBaseManager

### ğŸ“– ä½¿ç”¨è¯´æ˜

KnowledgeBaseManager æä¾›çŸ¥è¯†åº“ç®¡ç†åŠŸèƒ½ã€‚

#### åˆ›å»ºçŸ¥è¯†åº“

```typescript
const kb = await client.createKnowledgeBase({
  name: 'æˆ‘çš„çŸ¥è¯†åº“',
  description: 'é¡¹ç›®ç›¸å…³æ–‡æ¡£',
})
```

#### ä¸Šä¼ æ–‡æ¡£

```typescript
const doc = await client.uploadDocument(kb.id, '/path/to/doc.pdf')
console.log('æ–‡æ¡£ ID:', doc.id)
```

### ğŸ’¡ æŠ€å·§æŒ‡å—

#### 1. æ–‡æ¡£åˆ†ç±»

ä½¿ç”¨æ ‡ç­¾åˆ†ç±»æ–‡æ¡£ï¼š

```typescript
const tags = {
  api: ['æ–‡æ¡£', 'æ¥å£', 'API'],
  tutorial: ['æ•™ç¨‹', 'æŒ‡å—', 'å­¦ä¹ '],
  reference: ['å‚è€ƒ', 'æ‰‹å†Œ', 'æ–‡æ¡£'],
}

function categorizeDocument(filename: string): string[] {
  const lowerName = filename.toLowerCase()
  for (const [category, keywords] of Object.entries(tags)) {
    if (keywords.some(kw => lowerName.includes(kw))) {
      return tags[category]
    }
  }
  return tags.reference
}
```

### âŒ å¸¸è§é”™è¯¯åŠè§£å†³

#### é”™è¯¯ 1: Document parsing failed

**åŸå› ï¼š** æ–‡æ¡£è§£æå¤±è´¥

**è§£å†³æ–¹æ³•ï¼š**
1. æ£€æŸ¥æ–‡ä»¶æ ¼å¼
2. è½¬æ¢æ–‡ä»¶æ ¼å¼
3. ä½¿ç”¨æ”¯æŒçš„æ ¼å¼

```typescript
const supportedFormats = ['pdf', 'txt', 'md', 'json']
const ext = filename.split('.').pop()?.toLowerCase()

if (!supportedFormats.includes(ext)) {
  throw new Error(`ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: ${ext}`)
}
```

---

## MultiModalManager

### ğŸ“– ä½¿ç”¨è¯´æ˜

MultiModalManager æä¾›å¤šæ¨¡æ€åŠŸèƒ½ï¼ˆå›¾åƒã€è¯­éŸ³ã€è§†é¢‘ï¼‰ã€‚

#### å›¾åƒç”Ÿæˆ

```typescript
const image = await client.generateImage({
  model: 'cogview-3-flash',
  prompt: 'ä¸€åªå¯çˆ±çš„çŒ«å’ª',
  size: '1024x1024',
})
```

#### æ–‡æœ¬è½¬è¯­éŸ³

```typescript
const audio = await client.textToSpeech({
  model: 'glm-4v-flash',
  input: 'ä½ å¥½ï¼Œä¸–ç•Œ',
  voice: 'alloy',
  speed: 1.0,
})
```

### ğŸ’¡ æŠ€å·§æŒ‡å—

#### 1. æç¤ºè¯ä¼˜åŒ–

ä¼˜åŒ–å›¾åƒç”Ÿæˆæç¤ºè¯ï¼š

```typescript
function optimizePrompt(prompt: string): string {
  const modifiers = [
    'high quality',
    'detailed',
    'professional',
  ]
  return `${prompt}, ${modifiers.join(', ')}`
}
```

### âŒ å¸¸è§é”™è¯¯åŠè§£å†³

#### é”™è¯¯ 1: Model not available

**åŸå› ï¼š** æ¨¡å‹ä¸å¯ç”¨

**è§£å†³æ–¹æ³•ï¼š**
1. æ£€æŸ¥æ¨¡å‹åç§°
2. åˆ—å‡ºå¯ç”¨æ¨¡å‹
3. ä½¿ç”¨æ”¯æŒçš„æ¨¡å‹

```typescript
const availableModels = {
  image: ['cogview-3-flash', 'cogview-3'],
  audio: ['glm-4v-flash'],
  video: ['cogvideox-2'],
}

function validateModel(type: string, model: string): boolean {
  return availableModels[type].includes(model)
}
```

---

## ğŸ“‹ æœ€ä½³å®è·µ

### 1. é”™è¯¯å¤„ç†

å§‹ç»ˆä½¿ç”¨ try-catch å¤„ç†é”™è¯¯ï¼š

```typescript
try {
  const response = await client.chat(assistantId, messages)
} catch (error) {
  console.error('è¯·æ±‚å¤±è´¥:', error)
  // æ ¹æ®é”™è¯¯ç±»å‹é‡‡å–ä¸åŒçš„æ¢å¤ç­–ç•¥
}
```

### 2. èµ„æºæ¸…ç†

åŠæ—¶æ¸…ç†èµ„æºï¼š

```typescript
const cleanup = () => {
  // æ¸…ç†ç¼“å­˜
  messageCache.clear()
  // å…³é—­è¿æ¥
  // é‡Šæ”¾èµ„æº
}

process.on('exit', cleanup)
process.on('SIGINT', cleanup)
```

### 3. æ—¥å¿—è®°å½•

è®°å½•è¯¦ç»†çš„æ—¥å¿—ï¼š

```typescript
const logger = {
  info: (msg: string) => console.log(`[INFO] ${msg}`),
  error: (msg: string, error: any) => 
    console.error(`[ERROR] ${msg}`, error),
  debug: (msg: string) => 
    console.debug(`[DEBUG] ${msg}`),
}

logger.info('å¼€å§‹è¯·æ±‚...')
const response = await client.chat(assistantId, messages)
logger.info('è¯·æ±‚å®Œæˆ')
```

### 4. é…ç½®ç®¡ç†

ä½¿ç”¨é…ç½®æ–‡ä»¶ç®¡ç†é…ç½®ï¼š

```typescript
import config from './config.json'

const client = new BigModelClient({
  apiKey: config.apiKey,
  baseUrl: config.baseUrl,
  timeout: config.timeout,
})
```

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [BigModel-Z.ai SDK README](../README.md)
- [MCP é›†æˆæ–‡æ¡£](../mcp/README.md)
- [ç¤ºä¾‹ä»£ç ](../examples/README.md)
- [OpenAI å…¼å®¹æ–‡æ¡£](../examples/openai-compatible-example.ts)
