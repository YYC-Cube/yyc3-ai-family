/**
 * @file YYCÂ³ Family-Ï€Â³ å®Œæ•´æ¨¡å‹é…ç½®æ–¹æ¡ˆ
 * @description æ€»æŒ‡æŒ¥è§†è§’ - ååŒå…¨å±€æ¨¡å‹é…ç½®
 * @author YYCÂ³ Team
 * @version 2.0.0
 *
 * æˆæƒæ¨¡å‹ (æœ‰æˆæƒä¹¦):
 * - ChatGLM3-6B: å¼€æºå¯¹è¯æ¨¡å‹
 * - CodeGeeX4-ALL-9B: ä»£ç ç”Ÿæˆä¸“ç”¨
 * - CogAgent: GUIæ™ºèƒ½ä½“
 * - CogVideoX-5B: è§†é¢‘ç”Ÿæˆ
 *
 * é…ç½®ç­–ç•¥:
 * 1. æœ¬åœ°æ¨ç†ä¼˜å…ˆ - ä½å»¶è¿Ÿã€æ— æˆæœ¬
 * 2. äº‘ç«¯APIè¡¥å…… - é«˜èƒ½åŠ›ã€å¤æ‚ä»»åŠ¡
 * 3. æˆæƒæ¨¡å‹ä¸“ç”¨ - ç‰¹å®šåœºæ™¯
 * 4. Agentæ™ºèƒ½è·¯ç”± - ä»»åŠ¡åŒ¹é…
 */

// ============================================================
// Types
// ============================================================

export type ModelTier = 'local' | 'cloud-free' | 'cloud-paid' | 'authorized';
export type ModelCategory = 'reasoning' | 'coding' | 'conversation' | 'vision' | 'video' | 'automation';

export interface GlobalModelConfig {
  id: string;
  name: string;
  provider: string;
  tier: ModelTier;
  categories: ModelCategory[];
  contextWindow: number;
  maxOutput: number;
  supportsStreaming: boolean;
  supportsVision?: boolean;
  supportsTools?: boolean;

  // éƒ¨ç½²ä¿¡æ¯
  deployment: {
    local?: {
      available: boolean;
      nodes: string[];
      ollamaName?: string;
    };
    cloud?: {
      available: boolean;
      endpoint: string;
      requiresAuth: boolean;
    };
  };

  // æ€§èƒ½æŒ‡æ ‡
  performance?: {
    avgLatencyMs: number;
    p95LatencyMs: number;
    throughput: number;
    maxConcurrent: number;
  };

  // æˆæœ¬ä¿¡æ¯
  pricing: {
    inputPer1M: number;
    outputPer1M: number;
    isFree: boolean;
  };

  // Agentæ¨è
  recommendedAgents: string[];

  // æˆæƒä¿¡æ¯
  authorization?: {
    company: string;
    code: string;
    validity: string;
    certificatePath?: string;
  };
}

// ============================================================
// æ™ºè°±æˆæƒæ¨¡å‹é…ç½® (æœ‰æˆæƒä¹¦)
// ============================================================

export const AUTHORIZED_MODELS: GlobalModelConfig[] = [
  {
    id: 'CodeGeeX4-ALL-9B',
    name: 'CodeGeeX4-ALL-9B (æˆæƒ)',
    provider: 'zhipu',
    tier: 'authorized',
    categories: ['coding', 'reasoning'],
    contextWindow: 128000,
    maxOutput: 8192,
    supportsStreaming: true,
    supportsTools: true,
    deployment: {
      local: {
        available: true,
        nodes: ['m4-max', 'imac-m4'],
        ollamaName: 'codegeex4:latest',
      },
      cloud: {
        available: true,
        endpoint: 'https://open.bigmodel.cn/api/paas/v4',
        requiresAuth: true,
      },
    },
    performance: {
      avgLatencyMs: 5300,
      p95LatencyMs: 6200,
      throughput: 25,
      maxConcurrent: 3,
    },
    pricing: { inputPer1M: 0, outputPer1M: 0, isFree: true },
    recommendedAgents: ['bole', 'grandmaster'],
    authorization: {
      company: 'æ´›é˜³æ²«è¨€é…’åº—ç®¡ç†æœ‰é™å…¬å¸',
      code: '202411283053152737',
      validity: 'æ°¸ä¹…æœ‰æ•ˆ',
      certificatePath: '/Users/yanyu/YYC3-Mac-Max/æ™ºè°±æˆæƒä¹¦/ZhiPu_CodeGeeX4-ALL-9B.png',
    },
  },
  {
    id: 'ChatGLM3-6B',
    name: 'ChatGLM3-6B (æˆæƒ)',
    provider: 'zhipu',
    tier: 'authorized',
    categories: ['conversation', 'reasoning'],
    contextWindow: 8192,
    maxOutput: 2048,
    supportsStreaming: true,
    deployment: {
      local: {
        available: false, // éœ€è¦ç‰¹æ®Šéƒ¨ç½²
        nodes: [],
        ollamaName: 'chatglm3:6b',
      },
      cloud: {
        available: true,
        endpoint: 'https://open.bigmodel.cn/api/paas/v4',
        requiresAuth: true,
      },
    },
    pricing: { inputPer1M: 0, outputPer1M: 0, isFree: true },
    recommendedAgents: ['pivot'],
    authorization: {
      company: 'æ´›é˜³æ²«è¨€é…’åº—ç®¡ç†æœ‰é™å…¬å¸',
      code: '202411283053152737',
      validity: 'æ°¸ä¹…æœ‰æ•ˆ',
      certificatePath: '/Users/yanyu/YYC3-Mac-Max/æ™ºè°±æˆæƒä¹¦/ZhiPu_ChatGLM3-6B.png',
    },
  },
  {
    id: 'CogAgent',
    name: 'CogAgent (æˆæƒ)',
    provider: 'zhipu',
    tier: 'authorized',
    categories: ['vision', 'automation', 'reasoning'],
    contextWindow: 32000,
    maxOutput: 4096,
    supportsStreaming: true,
    supportsVision: true,
    supportsTools: true,
    deployment: {
      local: {
        available: false, // éœ€è¦GPUæ¨ç†
        nodes: [],
      },
      cloud: {
        available: true,
        endpoint: 'https://open.bigmodel.cn/api/paas/v4',
        requiresAuth: true,
      },
    },
    pricing: { inputPer1M: 0, outputPer1M: 0, isFree: true },
    recommendedAgents: ['navigator', 'sentinel'],
    authorization: {
      company: 'æ´›é˜³æ²«è¨€é…’åº—ç®¡ç†æœ‰é™å…¬å¸',
      code: '202411283053152737',
      validity: 'æ°¸ä¹…æœ‰æ•ˆ',
      certificatePath: '/Users/yanyu/YYC3-Mac-Max/æ™ºè°±æˆæƒä¹¦/ZhiPu_CogAgent.png',
    },
  },
  {
    id: 'CogVideoX-5B',
    name: 'CogVideoX-5B (æˆæƒ)',
    provider: 'zhipu',
    tier: 'authorized',
    categories: ['video', 'vision'],
    contextWindow: 8192,
    maxOutput: 2048,
    supportsStreaming: true,
    deployment: {
      local: {
        available: false, // éœ€è¦GPUæ¨ç†
        nodes: [],
      },
      cloud: {
        available: true,
        endpoint: 'https://open.bigmodel.cn/api/paas/v4',
        requiresAuth: true,
      },
    },
    pricing: { inputPer1M: 0, outputPer1M: 0, isFree: true },
    recommendedAgents: ['grandmaster'],
    authorization: {
      company: 'æ´›é˜³æ²«è¨€é…’åº—ç®¡ç†æœ‰é™å…¬å¸',
      code: '202411283053152737',
      validity: 'æ°¸ä¹…æœ‰æ•ˆ',
      certificatePath: '/Users/yanyu/YYC3-Mac-Max/æ™ºè°±æˆæƒä¹¦/ZhiPu_CogVideoX-5B.png',
    },
  },
];

// ============================================================
// æœ¬åœ°æ¨ç†æ¨¡å‹ (Ollama)
// ============================================================

export const LOCAL_MODELS: GlobalModelConfig[] = [
  {
    id: 'qwen2.5:7b',
    name: 'Qwen 2.5 7B (æœ¬åœ°)',
    provider: 'ollama',
    tier: 'local',
    categories: ['conversation', 'reasoning', 'coding'],
    contextWindow: 128000,
    maxOutput: 8192,
    supportsStreaming: true,
    deployment: {
      local: {
        available: true,
        nodes: ['m4-max'],
        ollamaName: 'qwen2.5:7b',
      },
    },
    performance: {
      avgLatencyMs: 2800,
      p95LatencyMs: 3200,
      throughput: 45,
      maxConcurrent: 4,
    },
    pricing: { inputPer1M: 0, outputPer1M: 0, isFree: true },
    recommendedAgents: ['navigator', 'thinker', 'prophet', 'pivot', 'sentinel'],
  },
  {
    id: 'glm4:9b',
    name: 'GLM-4 9B (æœ¬åœ°)',
    provider: 'ollama',
    tier: 'local',
    categories: ['conversation', 'reasoning'],
    contextWindow: 128000,
    maxOutput: 8192,
    supportsStreaming: true,
    deployment: {
      local: {
        available: true,
        nodes: ['imac-m4'],
        ollamaName: 'glm4:9b',
      },
    },
    performance: {
      avgLatencyMs: 5200,
      p95LatencyMs: 5800,
      throughput: 28,
      maxConcurrent: 2,
    },
    pricing: { inputPer1M: 0, outputPer1M: 0, isFree: true },
    recommendedAgents: ['bole', 'pivot', 'sentinel'],
  },
  {
    id: 'phi3:mini',
    name: 'Phi-3 Mini 3.8B (æœ¬åœ°)',
    provider: 'ollama',
    tier: 'local',
    categories: ['conversation', 'reasoning'],
    contextWindow: 128000,
    maxOutput: 8192,
    supportsStreaming: true,
    deployment: {
      local: {
        available: true,
        nodes: ['imac-m4'],
        ollamaName: 'phi3:mini',
      },
    },
    performance: {
      avgLatencyMs: 4900,
      p95LatencyMs: 6500,
      throughput: 55,
      maxConcurrent: 3,
    },
    pricing: { inputPer1M: 0, outputPer1M: 0, isFree: true },
    recommendedAgents: ['sentinel', 'pivot'],
  },
];

// ============================================================
// äº‘ç«¯APIæ¨¡å‹ (æ™ºè°±)
// ============================================================

export const ZHIPU_CLOUD_MODELS: GlobalModelConfig[] = [
  {
    id: 'GLM-4.7',
    name: 'GLM-4.7 (äº‘ç«¯)',
    provider: 'zhipu',
    tier: 'cloud-paid',
    categories: ['reasoning', 'coding', 'conversation'],
    contextWindow: 200000,
    maxOutput: 128000,
    supportsStreaming: true,
    supportsTools: true,
    deployment: {
      cloud: {
        available: true,
        endpoint: 'https://open.bigmodel.cn/api/paas/v4',
        requiresAuth: true,
      },
    },
    pricing: { inputPer1M: 0, outputPer1M: 0, isFree: false },
    recommendedAgents: ['navigator', 'thinker', 'grandmaster'],
  },
  {
    id: 'GLM-4.7-Flash',
    name: 'GLM-4.7 Flash (å…è´¹äº‘ç«¯)',
    provider: 'zhipu',
    tier: 'cloud-free',
    categories: ['conversation', 'reasoning'],
    contextWindow: 200000,
    maxOutput: 128000,
    supportsStreaming: true,
    deployment: {
      cloud: {
        available: true,
        endpoint: 'https://open.bigmodel.cn/api/paas/v4',
        requiresAuth: true,
      },
    },
    pricing: { inputPer1M: 0, outputPer1M: 0, isFree: true },
    recommendedAgents: ['pivot', 'sentinel'],
  },
  {
    id: 'GLM-4-Long',
    name: 'GLM-4 Long (1Mä¸Šä¸‹æ–‡)',
    provider: 'zhipu',
    tier: 'cloud-paid',
    categories: ['conversation', 'reasoning'],
    contextWindow: 1000000,
    maxOutput: 4096,
    supportsStreaming: true,
    deployment: {
      cloud: {
        available: true,
        endpoint: 'https://open.bigmodel.cn/api/paas/v4',
        requiresAuth: true,
      },
    },
    pricing: { inputPer1M: 0, outputPer1M: 0, isFree: false },
    recommendedAgents: ['pivot', 'grandmaster'],
  },
];

// ============================================================
// äº‘ç«¯APIæ¨¡å‹ (å…¶ä»–Provider)
// ============================================================

export const EXTERNAL_CLOUD_MODELS: GlobalModelConfig[] = [
  {
    id: 'gpt-4o',
    name: 'GPT-4o',
    provider: 'openai',
    tier: 'cloud-paid',
    categories: ['reasoning', 'coding', 'conversation', 'vision'],
    contextWindow: 128000,
    maxOutput: 16384,
    supportsStreaming: true,
    supportsVision: true,
    supportsTools: true,
    deployment: {
      cloud: {
        available: true,
        endpoint: 'https://api.openai.com/v1',
        requiresAuth: true,
      },
    },
    pricing: { inputPer1M: 2.5, outputPer1M: 10, isFree: false },
    recommendedAgents: ['thinker', 'grandmaster'],
  },
  {
    id: 'claude-sonnet-4-20250514',
    name: 'Claude 4 Sonnet',
    provider: 'anthropic',
    tier: 'cloud-paid',
    categories: ['reasoning', 'coding', 'conversation', 'vision'],
    contextWindow: 200000,
    maxOutput: 64000,
    supportsStreaming: true,
    supportsVision: true,
    supportsTools: true,
    deployment: {
      cloud: {
        available: true,
        endpoint: 'https://api.anthropic.com/v1',
        requiresAuth: true,
      },
    },
    pricing: { inputPer1M: 3, outputPer1M: 15, isFree: false },
    recommendedAgents: ['thinker', 'navigator', 'sentinel'],
  },
  {
    id: 'deepseek-chat',
    name: 'DeepSeek-V3',
    provider: 'deepseek',
    tier: 'cloud-paid',
    categories: ['reasoning', 'coding', 'conversation'],
    contextWindow: 128000,
    maxOutput: 8192,
    supportsStreaming: true,
    supportsTools: true,
    deployment: {
      cloud: {
        available: true,
        endpoint: 'https://api.deepseek.com/v1',
        requiresAuth: true,
      },
    },
    pricing: { inputPer1M: 0.14, outputPer1M: 0.28, isFree: false },
    recommendedAgents: ['navigator', 'bole', 'prophet'],
  },
  {
    id: 'deepseek-reasoner',
    name: 'DeepSeek-R1',
    provider: 'deepseek',
    tier: 'cloud-paid',
    categories: ['reasoning'],
    contextWindow: 128000,
    maxOutput: 8192,
    supportsStreaming: true,
    deployment: {
      cloud: {
        available: true,
        endpoint: 'https://api.deepseek.com/v1',
        requiresAuth: true,
      },
    },
    pricing: { inputPer1M: 0.55, outputPer1M: 2.2, isFree: false },
    recommendedAgents: ['thinker', 'prophet'],
  },
  {
    id: 'gemini-2.5-flash',
    name: 'Gemini 2.5 Flash (å…è´¹)',
    provider: 'google',
    tier: 'cloud-free',
    categories: ['reasoning', 'conversation', 'vision'],
    contextWindow: 1048576,
    maxOutput: 65536,
    supportsStreaming: true,
    supportsVision: true,
    deployment: {
      cloud: {
        available: true,
        endpoint: 'https://generativelanguage.googleapis.com/v1beta/openai',
        requiresAuth: true,
      },
    },
    pricing: { inputPer1M: 0, outputPer1M: 0, isFree: true },
    recommendedAgents: ['pivot', 'prophet'],
  },
];

// ============================================================
// Agent æ¨¡å‹è·¯ç”±ç­–ç•¥
// ============================================================

export interface AgentRoutingStrategy {
  agentId: string;
  agentName: string;
  primaryUseCase: string;
  modelPriority: {
    local: string[]; // æœ¬åœ°æ¨¡å‹ä¼˜å…ˆçº§
    authorized: string[]; // æˆæƒæ¨¡å‹ä¼˜å…ˆçº§
    cloud: string[]; // äº‘ç«¯æ¨¡å‹ä¼˜å…ˆçº§
  };
  fallbackChain: string[];
  temperature: number;
  maxTokens: number;
}

export const AGENT_ROUTING_STRATEGIES: Record<string, AgentRoutingStrategy> = {
  navigator: {
    agentId: 'navigator',
    agentName: 'æ™ºæ„ˆÂ·é¢†èˆªå‘˜',
    primaryUseCase: 'å…¨åŸŸèµ„æºè°ƒåº¦ä¸è·¯å¾„è§„åˆ’',
    modelPriority: {
      local: ['qwen2.5:7b'],
      authorized: ['CodeGeeX4-ALL-9B'],
      cloud: ['GLM-4.7', 'claude-sonnet-4-20250514', 'deepseek-chat'],
    },
    fallbackChain: ['qwen2.5:7b', 'GLM-4.7-Flash', 'GLM-4.7'],
    temperature: 0.3,
    maxTokens: 4096,
  },
  thinker: {
    agentId: 'thinker',
    agentName: 'æ´è§Â·æ€æƒ³å®¶',
    primaryUseCase: 'æ·±åº¦é€»è¾‘æ¨ç†ä¸å†³ç­–åˆ†æ',
    modelPriority: {
      local: ['qwen2.5:7b'],
      authorized: ['CodeGeeX4-ALL-9B'],
      cloud: ['claude-sonnet-4-20250514', 'deepseek-reasoner', 'gpt-4o'],
    },
    fallbackChain: ['qwen2.5:7b', 'deepseek-reasoner', 'claude-sonnet-4-20250514'],
    temperature: 0.5,
    maxTokens: 8192,
  },
  prophet: {
    agentId: 'prophet',
    agentName: 'é¢„è§Â·å…ˆçŸ¥',
    primaryUseCase: 'è¶‹åŠ¿é¢„æµ‹ä¸é£é™©å‰ç½®',
    modelPriority: {
      local: ['qwen2.5:7b'],
      authorized: [],
      cloud: ['deepseek-reasoner', 'GLM-4.7', 'gemini-2.5-flash'],
    },
    fallbackChain: ['qwen2.5:7b', 'deepseek-reasoner', 'gemini-2.5-flash'],
    temperature: 0.4,
    maxTokens: 4096,
  },
  bole: {
    agentId: 'bole',
    agentName: 'çŸ¥é‡Â·ä¼¯ä¹',
    primaryUseCase: 'æ¨¡å‹è¯„ä¼°ä¸ä¼˜é€‰åŒ¹é…',
    modelPriority: {
      local: ['codegeex4:latest', 'glm4:9b'],
      authorized: ['CodeGeeX4-ALL-9B'],
      cloud: ['GLM-4.7', 'deepseek-chat'],
    },
    fallbackChain: ['codegeex4:latest', 'GLM-4.7', 'deepseek-chat'],
    temperature: 0.3,
    maxTokens: 4096,
  },
  pivot: {
    agentId: 'pivot',
    agentName: 'å…ƒå¯Â·å¤©æ¢',
    primaryUseCase: 'æ ¸å¿ƒçŠ¶æ€ç®¡ç†ä¸ä¸Šä¸‹æ–‡',
    modelPriority: {
      local: ['qwen2.5:7b', 'phi3:mini'],
      authorized: ['ChatGLM3-6B'],
      cloud: ['GLM-4-Long', 'GLM-4.7-Flash', 'gemini-2.5-flash'],
    },
    fallbackChain: ['qwen2.5:7b', 'GLM-4.7-Flash', 'GLM-4-Long'],
    temperature: 0.2,
    maxTokens: 4096,
  },
  sentinel: {
    agentId: 'sentinel',
    agentName: 'å«å®‰Â·å“¨å…µ',
    primaryUseCase: 'å®‰å…¨è¾¹ç•Œé˜²æŠ¤ä¸å®¡è®¡',
    modelPriority: {
      local: ['qwen2.5:7b', 'phi3:mini'],
      authorized: ['CogAgent'],
      cloud: ['claude-sonnet-4-20250514', 'GLM-4.7-Flash'],
    },
    fallbackChain: ['qwen2.5:7b', 'GLM-4.7-Flash', 'claude-sonnet-4-20250514'],
    temperature: 0.1,
    maxTokens: 4096,
  },
  grandmaster: {
    agentId: 'grandmaster',
    agentName: 'æ ¼ç‰©Â·å®—å¸ˆ',
    primaryUseCase: 'çŸ¥è¯†åº“æ„å»ºä¸æœ¬ä½“è®º',
    modelPriority: {
      local: ['codegeex4:latest'],
      authorized: ['CodeGeeX4-ALL-9B', 'CogVideoX-5B'],
      cloud: ['gpt-4o', 'GLM-4.7', 'claude-sonnet-4-20250514'],
    },
    fallbackChain: ['codegeex4:latest', 'GLM-4.7', 'gpt-4o'],
    temperature: 0.4,
    maxTokens: 8192,
  },
};

// ============================================================
// å…¨å±€æ¨¡å‹æ³¨å†Œè¡¨
// ============================================================

class GlobalModelRegistry {
  private allModels = new Map<string, GlobalModelConfig>();

  constructor() {
    this.loadModels();
  }

  private loadModels(): void {
    [
      ...AUTHORIZED_MODELS,
      ...LOCAL_MODELS,
      ...ZHIPU_CLOUD_MODELS,
      ...EXTERNAL_CLOUD_MODELS,
    ].forEach(model => {
      this.allModels.set(model.id, model);
    });
  }

  getAllModels(): GlobalModelConfig[] {
    return Array.from(this.allModels.values());
  }

  getModel(id: string): GlobalModelConfig | undefined {
    return this.allModels.get(id);
  }

  getModelsByTier(tier: ModelTier): GlobalModelConfig[] {
    return this.getAllModels().filter(m => m.tier === tier);
  }

  getModelsByCategory(category: ModelCategory): GlobalModelConfig[] {
    return this.getAllModels().filter(m => m.categories.includes(category));
  }

  getLocalAvailableModels(): GlobalModelConfig[] {
    return this.getAllModels().filter(m => m.deployment.local?.available);
  }

  getAuthorizedModels(): GlobalModelConfig[] {
    return this.getAllModels().filter(m => m.tier === 'authorized');
  }

  getAgentRoutingStrategy(agentId: string): AgentRoutingStrategy | undefined {
    return AGENT_ROUTING_STRATEGIES[agentId];
  }

  getBestModelForAgent(agentId: string, preferLocal = true): GlobalModelConfig | undefined {
    const strategy = AGENT_ROUTING_STRATEGIES[agentId];

    if (!strategy) return undefined;

    // ä¼˜å…ˆæœ¬åœ°æ¨¡å‹
    if (preferLocal) {
      for (const modelId of strategy.modelPriority.local) {
        const model = this.getModel(modelId);

        if (model?.deployment.local?.available) {
          return model;
        }
      }
    }

    // å›é€€é“¾
    for (const modelId of strategy.fallbackChain) {
      const model = this.getModel(modelId);

      if (model) {
        if (model.deployment.local?.available || model.deployment.cloud?.available) {
          return model;
        }
      }
    }

    return undefined;
  }
}

export const globalModelRegistry = new GlobalModelRegistry();

// ============================================================
// Helper Functions
// ============================================================

export function getModelSummary(): {
  total: number;
  byTier: Record<ModelTier, number>;
  localAvailable: number;
  authorized: number;
  } {
  const models = globalModelRegistry.getAllModels();

  return {
    total: models.length,
    byTier: {
      local: models.filter(m => m.tier === 'local').length,
      'cloud-free': models.filter(m => m.tier === 'cloud-free').length,
      'cloud-paid': models.filter(m => m.tier === 'cloud-paid').length,
      authorized: models.filter(m => m.tier === 'authorized').length,
    },
    localAvailable: models.filter(m => m.deployment.local?.available).length,
    authorized: models.filter(m => m.tier === 'authorized').length,
  };
}

export function printModelMatrix(): string {
  const lines: string[] = [
    '# YYCÂ³ æ¨¡å‹é…ç½®çŸ©é˜µ',
    '',
    '## æˆæƒæ¨¡å‹ (æœ‰æˆæƒä¹¦)',
    '',
    '| æ¨¡å‹ | ç”¨é€” | æœ¬åœ°å¯ç”¨ | äº‘ç«¯å¯ç”¨ | æ¨èAgent |',
    '|------|------|----------|----------|-----------|',
  ];

  AUTHORIZED_MODELS.forEach(m => {
    const local = m.deployment.local?.available ? 'âœ…' : 'âŒ';
    const cloud = m.deployment.cloud?.available ? 'âœ…' : 'âŒ';

    lines.push(`| ${m.name} | ${m.categories.join(', ')} | ${local} | ${cloud} | ${m.recommendedAgents.join(', ')} |`);
  });

  lines.push('', '## æœ¬åœ°æ¨ç†æ¨¡å‹', '');
  lines.push('| æ¨¡å‹ | èŠ‚ç‚¹ | å»¶è¿Ÿ | æ¨èAgent |');
  lines.push('|------|------|------|-----------|');

  LOCAL_MODELS.forEach(m => {
    const nodes = m.deployment.local?.nodes.join(', ') || '-';
    const latency = m.performance ? `${m.performance.avgLatencyMs}ms` : '-';

    lines.push(`| ${m.name} | ${nodes} | ${latency} | ${m.recommendedAgents.join(', ')} |`);
  });

  lines.push('', '## äº‘ç«¯APIæ¨¡å‹', '');
  lines.push('| æ¨¡å‹ | Provider | å…è´¹ | æ¨èAgent |');
  lines.push('|------|----------|------|-----------|');

  [...ZHIPU_CLOUD_MODELS, ...EXTERNAL_CLOUD_MODELS].forEach(m => {
    const free = m.pricing.isFree ? 'âœ…' : 'ğŸ’°';

    lines.push(`| ${m.name} | ${m.provider} | ${free} | ${m.recommendedAgents.join(', ')} |`);
  });

  return lines.join('\n');
}
