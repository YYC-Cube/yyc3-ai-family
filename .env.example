# ============================================================
# YYC3 Hacker Chatbot — Environment Variables Template
# Phase 33: Development Environment Bootstrap
#
# This file lives at config/env.example (Figma Make 不导出 dotfiles)
# setup.sh 会自动复制为 .env.example / .env.local
#
# Vite loads .env files in this priority (highest first):
#   .env.local > .env.[mode].local > .env.[mode] > .env
#
# All variables MUST start with VITE_ to be exposed to the client.
# NEVER put real secrets in committed .env files!
# ============================================================

# ============================================================
# 1. NAS Infrastructure (TerraMaster F4-423)
# ============================================================

# NAS host IP (LAN)
VITE_NAS_HOST=192.168.3.45

# SQLite HTTP Proxy (sqlite-http-api Docker container)
VITE_NAS_SQLITE_PORT=8484

# Docker Engine API (TCP 2375 must be enabled on NAS)
VITE_NAS_DOCKER_PORT=2375

# Family Heartbeat WebSocket
VITE_HEARTBEAT_WS_HOST=192.168.3.45
VITE_HEARTBEAT_WS_PORT=9090
VITE_HEARTBEAT_WS_PATH=/ws/heartbeat

# ============================================================
# 2. Cluster Device IPs (4-node home cluster)
# ============================================================

# MacBook Pro M4 Max (master node)
VITE_DEVICE_M4_MAX=192.168.3.22

# iMac M4 (render / secondary node)
VITE_DEVICE_IMAC_M4=192.168.3.77

# MateBook X Pro (edge / mobile node)
VITE_DEVICE_MATEBOOK=192.168.3.66

# YanYuCloud NAS (data center node)
VITE_DEVICE_NAS=192.168.3.45

# ============================================================
# 3. LLM Provider API Keys
#    Security: Keys stored ONLY in browser localStorage.
#    These are fallback/presets; configure in UI Settings preferred.
# ============================================================

# OpenAI (GPT-4o / GPT-4o-mini)
VITE_OPENAI_API_KEY=

# Anthropic (Claude 3.5 Sonnet / Haiku)
VITE_ANTHROPIC_API_KEY=

# DeepSeek (DeepSeek-V3 / R1)
VITE_DEEPSEEK_API_KEY=

# Zhipu Z.AI (GLM-4-Plus / GLM-4-Flash)
VITE_ZHIPU_API_KEY=

# Google AI (Gemini 2.0 Flash)
VITE_GOOGLE_API_KEY=

# Groq (llama / mixtral / gemma)
VITE_GROQ_API_KEY=

# ============================================================
# 4. Local LLM Services
# ============================================================

# Ollama (local inference)
VITE_OLLAMA_HOST=localhost
VITE_OLLAMA_PORT=11434

# LM Studio (local inference)
VITE_LMSTUDIO_HOST=localhost
VITE_LMSTUDIO_PORT=1234

# ============================================================
# 5. Application Configuration
# ============================================================

# Persistence strategy: 'localStorage' (default) | 'nasSqlite'
VITE_PERSISTENCE_STRATEGY=localStorage

# Metrics archive interval (ms), default 30s
VITE_METRICS_ARCHIVE_INTERVAL=30000

# Heartbeat simulation interval (ms), only when NAS offline
VITE_HEARTBEAT_SIMULATION_INTERVAL=8000

# Log level: 'debug' | 'info' | 'warn' | 'error'
VITE_LOG_LEVEL=info

# ============================================================
# 6. Express Backend (optional, for standalone deployment)
# ============================================================

# REST API Base URL
VITE_API_BASE_URL=http://localhost:3001/api

# WebSocket URL
VITE_WS_URL=ws://localhost:3001/ws

# ============================================================
# 7. KB Backend Services (Phase 32, NAS Docker containers)
# ============================================================

# Vector search service (Chroma / FAISS)
VITE_KB_VECTOR_PORT=8090

# OCR/ASR multimodal service (PaddleOCR + Whisper)
VITE_KB_MULTIMODAL_PORT=8091

# Knowledge graph NER + Neo4j (HanLP + BERT-NER)
VITE_KB_NLP_PORT=8092
